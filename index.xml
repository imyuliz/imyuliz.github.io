<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>yulibaozi</title>
    <link>https://yulibaozi.com/</link>
    <description>Recent content on yulibaozi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Tue, 21 Apr 2020 20:47:34 +0800</lastBuildDate>
    
	<atom:link href="https://yulibaozi.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kubernetes高级调度- Taint和Toleration、Node Affinity分析</title>
      <link>https://yulibaozi.com/posts/kubernetes/knowledge/2019-06-24-advanced-scheduling/</link>
      <pubDate>Tue, 21 Apr 2020 20:47:34 +0800</pubDate>
      
      <guid>https://yulibaozi.com/posts/kubernetes/knowledge/2019-06-24-advanced-scheduling/</guid>
      <description>Kubernetes高级调度- Taint和Toleration、Node Affinity分析 节点即Node
一、Taint和Toleration 污点的理论支撑 1.污点设置有哪些影响效果 使用效果(Effect):
 PreferNoSchedule:调度器尽量避免把Pod调度到具有该污点效果的节点上,如果不能避免(如其他节点资源不足),Pod也能调度到这个污点节点上。 NoSchedule:不容忍该污点效果的Pod永不会被调度到该节点上，通过kubelet管理的Pod(static Pod)不受限制;之前没有设置污点的Pod如果已运行在此节点(有污点的节点)上，可以继续运行。 NoExecute: 调度器不会把Pod调度到具有该污点效果的节点上，同时会将节点上已存在的Pod驱逐出去。  污点设置的第一前提是: 节点上的污点key和Pod上的污点容忍key相匹配。
2. 设置污点的效果实测 当Pod未设置污点容忍而节点设置了污点时  当节点的污点影响效果被设置为:PreferNoSchedule时,已存在于此节点上的Pod不会被驱逐；新增但未设置污点容忍的Pod仍然可以被调度到此节点上。 当节点的污点影响效果被设置为:NoSchedule时,已存在于此节点上的Pod不会被驱逐;同时,新增的Pod不会被调度此节点上. 当节点的污点影响效果被设置为:NoExecute时,已存在于此节点上的Pod会发生驱逐(驱逐时间由tolerationSeconds字段确定,小于等于0会立即驱逐);新增的Pod不会调度到此节点上。  以上所说的Pod未设置任何的污点容忍时
当Node设置了污点且Pod设置了对应的污点容忍时    Pod容忍效果 Node污点效果 是否会调度到此Node上 原因     PreferNoSchedule PreferNoSchedule √ Node的污点效果和Pod的容忍效果相匹配   PreferNoSchedule NoSchedule x Node的污点效果高于Pod的容忍效果   PreferNoSchedule NoExecute x Node的污点效果高于Pod的容忍效果   NoSchedule PreferNoSchedule √ Node的污点效果低于Pod的容忍效果   NoSchedule NoSchedule √ Node的污点效果和Pod的容忍效果相匹配   NoSchedule NoExecute x Node的污点效果高于Pod设置的容忍效果   NoExecute PreferNoSchedule √ Node的污点效果低于Pod的容忍效果   NoExecute NoSchedule x Node的污点效果和Pod的容忍程度互斥   NoExecute NoExecute x Pod在Node上不断重建和杀掉。    污点容忍设置, Exists和Equal这两个操作符之间的区别是什么?</description>
    </item>
    
    <item>
      <title>[译]使用 Kubebuilder 开发 Operator</title>
      <link>https://yulibaozi.com/posts/kubernetes/extend/2020-04-22-use-kubebuilder-to-operator/</link>
      <pubDate>Tue, 21 Apr 2020 01:10:50 +0800</pubDate>
      
      <guid>https://yulibaozi.com/posts/kubernetes/extend/2020-04-22-use-kubebuilder-to-operator/</guid>
      <description>写给那些人 原文地址
写给那些Kubernetes用户 Kubernetes用户将通过学习API的设计和实现背后的基本概念，更深入的理解Kubernetes。本书将教会读者怎样开发自己的Kubernetes APIs 和学习Kubernetes API核心的设计原则。
包括:
 Kubernetes API和resource的结构设计 API 版本语义 自托管/自愈 垃圾回收和终结器 声明式和命令式APIs 基于级别和基于边缘的APIs 资源和子资源  Kubernetes API 扩展开发 API 扩展开发者将学习到实现Kubernetes API背后的原理，概念和实现规范，以及用户快速开发的简单工具和库。 这本书涵盖了开发人员遇到的陷阱和思维上的误区。
包括:
 如果将多个事件批处理为单次调用对比,(翻译疑问) 如何配置定期对比 即将有的 如何使用缓存和实时查找 垃圾收集和终结器 如何使用声明与Webhook验证 如何实现API版本控制  快速开始 安装 安装Kubebuilder:
os=$(go env GOOS) arch=$(go env GOARCH) # download kubebuilder and extract it to tmp curl -sL https://go.kubebuilder.io/dl/2.0.0-alpha.2/${os}/${arch} | tar -xz -C /tmp/ # move to a long-term location and put it on your path # (you&#39;ll need to set the KUBEBUILDER_ASSETS env var if you put it somewhere else) sudo mv /tmp/kubebuilder_2.</description>
    </item>
    
    <item>
      <title>Link</title>
      <link>https://yulibaozi.com/link/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yulibaozi.com/link/</guid>
      <description> 这里收藏这一些开发利器, 在需要时, 能够节约一大笔时间
性能优化指南  火焰图  常用工具  Json.cn beJson journalctl-cn yaml check 在线工具 GoLibs JSON TO GO JWT  </description>
    </item>
    
    <item>
      <title>[Beku] 如何使用三行代码发布你的应用到Kubernetes</title>
      <link>https://yulibaozi.com/posts/kubernetes/extend/2018-12-03-beku/</link>
      <pubDate>Sat, 21 Mar 2020 20:15:22 +0800</pubDate>
      
      <guid>https://yulibaozi.com/posts/kubernetes/extend/2018-12-03-beku/</guid>
      <description>beku的概要 众所周知，Kubernetes主要分为两大部分:部署时和运行时,Beku的定位在部署时,无需任何额外的心智负担,快速编写Kubernetes资源对象然后发布到到Kubernetes集群，这对那些开发PaaS平台的公司来说显得尤其重要,尤其是在前后端人员接口对接时和资安全保障。beku就是这样, 一个Golang人性化Kubernetes资源对象创建库,极简，无额外心智负担。
beku的初衷  部署应用时：
 beku期望同僚们在发布应用的时候,
 不用担心某个字段应该放在yaml或者json的那个层级(比如:imagePullSecrets这个字段我应该填在Pod里面还是Containers里,还是Deployment里,可能你一会记得,过一段时间你又不记得了); 也不用顾虑这个字段名是否填写正确,字段所对应的值是否符合Kubernetes要求（比如:imagepullsecrets应该是imagePullSecrets还是imagePullSecret呢; 更不用忧虑重复填写某字段不一致导致发布失败(比如:我们在使用Deployment的时候，通常会填写Pod的Labels,然后填写Deployment的Selectors,如果你需要Service时，还需要填写Service的Selectors,这可能会因为某个很小的错误填写导致发布不符合预期,引发这样的错误其实是很没必要的)等一些这些没必要担心的问题。   Paas平台研发时:
 beku期望同僚们在开发PaaS平台前后端对接时，后端开发者不用把Kubernetes资源对象的json和交给前端填写，由于在于Kubernetes资源对象的层级比较偏复杂，这需要时间成本沟通；在沟通层级的时候，还需要沟通相关的字段，这会分散前端开发者的精力和增加开发耗时；另一方面可能也会带来安全上面的问题，比如:某些存在不怀好意的人会尝试填写其他字段来试图攻击你的应用。如果使用beku，你可以很好的解决上面的问题，在解决和前端沟通成本和减少开发的时间成本时，安全也得到了保障，后端也增加了掌控能力,同时也达到了快速开发的目地,岂不美哉, 我们仍然举个示例来说明,假设我们在开发Deployment和Service的联合发布,前端可能只需要传入:
 { &amp;quot;name&amp;quot;:&amp;quot;httpd&amp;quot;, &amp;quot;namespace&amp;quot;:&amp;quot;yulibaozi&amp;quot;, &amp;quot;serviceType&amp;quot;:&amp;quot;NodePort&amp;quot;, &amp;quot;port&amp;quot;:&amp;quot;8080&amp;quot;, &amp;quot;replics&amp;quot;:2 }  前端只需要传入这些必要的字段,然后调用beku就可以发布Deployment和Service两个Kubernetes资源对象到Kubernetes了,是不是很惊叹太过简单了，你可能还会忧虑高阶需求能否得到满足,beku当然能满足,比如环境变量，挂载ceph和NFS等，不过这些都是选填,你可以很轻松的找到对他们的支持。
beku的特性  自动发布资源对象到Kubernetes 灵活的自定义开发 极简的JSON和YAML输入/输出 自动判断资源对象的必要字段 人性化的资源对象关联发布 严谨的QOS等级设置 准确的字段自动填充 写意的链式调用  使用示例 接下来,我们以一个示例来说明如何使用beku? 这次示例的的目标是Deployment和Service的关联发布?
使用beku创建deployment资源:
dp, err := beku.NewDeployment().SetNamespaceAndName(&amp;quot;yulibaozi&amp;quot;, &amp;quot;http&amp;quot;). SetPodLabels(map[string]string{&amp;quot;app&amp;quot;: &amp;quot;http&amp;quot;}).SetContainer(&amp;quot;http&amp;quot;, &amp;quot;wucong60/kube-node-demo1:v1&amp;quot;, 8081).Finish() if err != nil { panic(err) }  接下来使用已有的Deployment的创建Service:
svc, err := beku.DeploymentToSvc(dp, beku.ServiceTypeNodePort, false) if err !</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://yulibaozi.com/about/</link>
      <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yulibaozi.com/about/</guid>
      <description>你好，我是 yulibaozi，有任何建议或问题欢迎随时找我交流。
联系方式：
 Github：https://github.com/yulibaozi 公众号：未来会有的 邮箱：yulibaozi@qq.com  </description>
    </item>
    
    <item>
      <title>收集kubernetes控制台日志及元数据(fluent-bit&#43;elasticsearch&#43;kibana搭建)</title>
      <link>https://yulibaozi.com/posts/kubernetes/deploy/2019-12-21-fluent-bit&#43;elasticsearch&#43;kibana/</link>
      <pubDate>Sat, 21 Dec 2019 20:29:20 +0800</pubDate>
      
      <guid>https://yulibaozi.com/posts/kubernetes/deploy/2019-12-21-fluent-bit&#43;elasticsearch&#43;kibana/</guid>
      <description>#### 前要   kubectl version
 Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.3&amp;quot;, GitCommit:&amp;quot;d2835416544f298c919e2ead3be3d0864b52323b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-02-07T12:22:21Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;} Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;9&amp;quot;, GitVersion:&amp;quot;v1.9.3&amp;quot;, GitCommit:&amp;quot;d2835416544f298c919e2ead3be3d0864b52323b&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, BuildDate:&amp;quot;2018-02-07T11:55:20Z&amp;quot;, GoVersion:&amp;quot;go1.9.2&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}   namespace
 如果需要部署在非kube-system命令下,需要该所有yaml的namespace,例如:我所有的资源部署在logging这个namespace下。
 下载相关代码(主要是yaml文件)
 《elasticsearch、kibana》 https://github.com/kubernetes/kubernetes.git
《fluent-bit》 https://github.com/fluent/fluent-bit-kubernetes-logging.git
首先部署elasticsearch yaml目录:cluster/addons/fluentd-elasticsearch
 部署statefulset
kubectl create -f es-statefulset.yaml  我部署的时候镜像版本是:k8s.gcr.io/elasticsearch:v6.2.4
  初始化镜像: alpine:3.6
 部署configmap
kubectl create -f fluentd-es-configmap.yaml  部署Service
kubectl create -f es-service.yaml  查看service的信息并记下来,下面要用</description>
    </item>
    
    <item>
      <title>用 GODEBUG 看 GC</title>
      <link>https://yulibaozi.com/posts/go/tools/2019-09-02-godebug-gc/</link>
      <pubDate>Mon, 02 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://yulibaozi.com/posts/go/tools/2019-09-02-godebug-gc/</guid>
      <description>什么是 GC 在计算机科学中，垃圾回收（GC）是一种自动管理内存的机制，垃圾回收器会去尝试回收程序不再使用的对象及其占用的内存。而最早 John McCarthy 在 1959 年左右发明了垃圾回收，以简化 Lisp 中的手动内存管理的机制（来自 wikipedia）。
为什么要 GC 手动管理内存挺麻烦，管错或者管漏内存也很糟糕，将会直接导致程序不稳定（持续泄露）甚至直接崩溃。
GC 带来的问题 硬要说会带来什么问题的话，也就数大家最关注的 Stop The World（STW），STW 代指在执行某个垃圾回收算法的某个阶段时，需要将整个应用程序暂停去处理 GC 相关的工作事项。例如：
   行为 会不会 STW 为什么     标记开始 会 在开始标记时，准备根对象的扫描，会打开写屏障（Write Barrier） 和 辅助GC（mutator assist），而回收器和应用程序是并发运行的，因此会暂停当前正在运行的所有 Goroutine。   并发标记中 不会 标记阶段，主要目的是标记堆内存中仍在使用的值。   标记结束 会 在完成标记任务后，将重新扫描部分根对象，这时候会禁用写屏障（Write Barrier）和辅助GC（mutator assist），而标记阶段和应用程序是并发运行的，所以在标记阶段可能会有新的对象产生，因此在重新扫描时需要进行 STW。    如何调整 GC 频率 可以通过 GOGC 变量设置初始垃圾收集器的目标百分比值，对比的规则为当新分配的数值与上一次收集后剩余的实时数值的比例达到设置的目标百分比时，就会触发 GC，默认值为 GOGC=100。如果将其设置为 GOGC=off 可以完全禁用垃圾回收器，要不试试？
简单来讲就是，GOGC 的值设置的越大，GC 的频率越低，但每次最终所触发到 GC 的堆内存也会更大。</description>
    </item>
    
    <item>
      <title>自研程序如何快速对接kubernetes</title>
      <link>https://yulibaozi.com/posts/kubernetes/extend/2019-01-11-incluster-use-kubernetes/</link>
      <pubDate>Wed, 21 Aug 2019 20:33:22 +0800</pubDate>
      
      <guid>https://yulibaozi.com/posts/kubernetes/extend/2019-01-11-incluster-use-kubernetes/</guid>
      <description>实践kubernetes版本:v1.11.3
伟大之路 伟大的程序想要跑起来都是要经过磨难的，像我这个伟大的程序想在kubernetes集群内(Pod内)访问kube-apiserver接口,出现错误:
Get Enpoints err:endpoints &amp;quot;kubernetes&amp;quot; is forbidden: User &amp;quot;system:serviceaccount:yulibaozi:default&amp;quot; cannot get endpoints in the namespace &amp;quot;default&amp;quot;  而我伟大的程序是这样:
func main() { conf, err := rest.InClusterConfig() if err != nil { log.Fatalf(&amp;quot;InClusterConfig err:%v&amp;quot;, err) } client, err := kubernetes.NewForConfig(conf) if err != nil { log.Fatalf(&amp;quot;NewForConfig err:%v&amp;quot;, err) } for { ep, err := client.CoreV1().Endpoints(&amp;quot;default&amp;quot;).Get(&amp;quot;kubernetes&amp;quot;, metav1.GetOptions{}) if err != nil { log.Printf(&amp;quot;Get Enpoints err:%v&amp;quot;, err) } else { log.Printf(&amp;quot;%+v&amp;quot;, ep) } time.</description>
    </item>
    
    <item>
      <title>用 GODEBUG 看调度跟踪</title>
      <link>https://yulibaozi.com/posts/go/tools/2019-08-19-godebug-sched/</link>
      <pubDate>Mon, 19 Aug 2019 12:00:00 +0000</pubDate>
      
      <guid>https://yulibaozi.com/posts/go/tools/2019-08-19-godebug-sched/</guid>
      <description>让 Go 更强大的原因之一莫过于它的 GODEBUG 工具，GODEBUG 的设置可以让 Go 程序在运行时输出调试信息，可以根据你的要求很直观的看到你想要的调度器或垃圾回收等详细信息，并且还不需要加装其它的插件，非常方便，今天我们将先讲解 GODEBUG 的调度器相关内容，希望对你有所帮助。
不过在开始前，没接触过的小伙伴得先补补如下前置知识，便于更好的了解调试器输出的信息内容。
前置知识 Go scheduler 的主要功能是针对在处理器上运行的 OS 线程分发可运行的 Goroutine，而我们一提到调度器，就离不开三个经常被提到的缩写，分别是：
 G：Goroutine，实际上我们每次调用 go func 就是生成了一个 G。 P：处理器，一般为处理器的核数，可以通过 GOMAXPROCS 进行修改。 M：OS 线程  这三者交互实际来源于 Go 的 M: N 调度模型，也就是 M 必须与 P 进行绑定，然后不断地在 M 上循环寻找可运行的 G 来执行相应的任务，如果想具体了解可以详细阅读 《Go Runtime Scheduler》，我们抽其中的工作流程图进行简单分析，如下:
 当我们执行 go func() 时，实际上就是创建一个全新的 Goroutine，我们称它为 G。 新创建的 G 会被放入 P 的本地队列（Local Queue）或全局队列（Global Queue）中，准备下一步的动作。 唤醒或创建 M 以便执行 G。 不断地进行事件循环 寻找在可用状态下的 G 进行执行任务 清除后，重新进入事件循环  而在描述中有提到全局和本地这两类队列，其实在功能上来讲都是用于存放正在等待运行的 G，但是不同点在于，本地队列有数量限制，不允许超过 256 个。并且在新建 G 时，会优先选择 P 的本地队列，如果本地队列满了，则将 P 的本地队列的一半的 G 移动到全局队列，这其实可以理解为调度资源的共享和再平衡。</description>
    </item>
    
    <item>
      <title>Deployment和StatefulSet的使用理念和区别</title>
      <link>https://yulibaozi.com/posts/kubernetes/extend/2019-07-23-deployment-vs-statefulset/</link>
      <pubDate>Tue, 23 Jul 2019 20:36:50 +0800</pubDate>
      
      <guid>https://yulibaozi.com/posts/kubernetes/extend/2019-07-23-deployment-vs-statefulset/</guid>
      <description>### 理论上的区别  StatefulSet作为Kubernetes中部署应用的控制器之一,它被专门用于部署那些有状态和有持久化需求的应用,同时,它也遵循一些指定的规则。另一方面,我们熟知的Deployment也是做相似的事情。除了Kubernetes 文档中非常明确的指出:&amp;ldquo;如果应用不需要稳定的标识或者有序的部署,删除和缩放,你应该使用无状态的副本控制器部署你的应用,这些无状态的副本控制器(例如:Deployment,ReplicaSet)或许更适合你应用的无状态需求&amp;rdquo;。
If an application doesn’t require any stable identifiers or ordered deployment, deletion, or scaling, you should deploy your application with a controller that provides a set of stateless replicas. Controllers such as Deployment or Replica Set may be better suited to your stateless needs.
上面已经说明了StatefulSet和stateless replicas之间的区别,接下来,我们仔细看看:
   Deployment StatefulSet     可以扩展更多的副本集(ReplicaSet/RS)以支持更大的负载 有序,优雅的部署和扩展(缩放)   滚动更新是根据Deployment中的PodTemplateSpec配置完成的;当一个新的ReplicaSet(RS)被新建时，Deployment会以指定的速率将Pod从旧的RS升级到新的RS,直到更新完成 有序,自动滚动更新   回滚:可以回滚到上一个/更早的版本 没有回滚,只有删除和缩小副本数   有独立的网络服务 StatefulSets目前要求Headless Service负责Pod在网络中的唯一身份    从上面的表格可以非常有底气的假设两者之间最大的区别在于网络服务的要求和StatefulSet的持久化存的储示例文档。但是,眼睛看到的不一定就是全部。</description>
    </item>
    
  </channel>
</rss>